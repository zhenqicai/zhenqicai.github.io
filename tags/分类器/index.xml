<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>分类器 on 秋码分享</title><link>https://qiucode.cn/tags/%E5%88%86%E7%B1%BB%E5%99%A8/</link><description>Recent content in 分类器 on 秋码分享</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Wed, 03 Apr 2024 15:43:43 +0800</lastBuildDate><atom:link href="https://qiucode.cn/tags/%E5%88%86%E7%B1%BB%E5%99%A8/index.xml" rel="self" type="application/rss+xml"/><item><title>多类别分类器（Machine Learning 研习十八）</title><link>https://qiucode.cn/article/198/</link><pubDate>Wed, 03 Apr 2024 15:43:43 +0800</pubDate><guid>https://qiucode.cn/article/198/</guid><description>多类别分类器 二元分类器可以区分两个类别，而多类别分类器（也称为多叉分类器）可以区分两个以上的类别。
一些 Scikit-Learn 分类器（如 LogisticRegression、RandomForestClassifier 和 GaussianNB）能够原生处理多个类别。其他分类器则是严格的二进制分类器（如 SGDClassifier 和 SVC）。不过，您可以使用多种策略来使用多个二进制分类器执行多类分类。
要创建一个能将数字图像分为 10 类（从 0 到 9）的系统，一种方法是训练 10 个二进制分类器，每个数字一个（0-检测器、1-检测器、2-检测器，以此类推）。然后，当您想对一幅图像进行分类时，您可以从每个分类器中得到该图像的判定分数，然后选择分类器输出分数最高的类别。这就是所谓的 &amp;ldquo;以一敌百&amp;rdquo;（OvR）策略，有时也称为 &amp;ldquo;以一敌众&amp;rdquo;（OvA）策略。
另一种策略是为每一对数字训练一个二元分类器：一个用于区分 0 和 1，另一个用于区分 0 和 2，还有一个用于区分 1 和 2，以此类推。这就是所谓的一对一（OvO）策略。如果有 N 个类别，则需要训练 N × (N - 1) / 2 个分类器。对于 MNIST 问题，这意味着要训练 45 个二进制分类器！当你想对一幅图像进行分类时，你必须让图像通过所有 45 个分类器，看看哪个分类器赢得了最多的对决。OvO 的主要优势在于，每个分类器只需在训练集中包含其必须区分的两个类别的部分进行训练。
有些算法（如支持向量机分类器）随训练集的大小而缩放，效果不佳。对于这些算法，OvO 是首选，因为在小训练集上训练多个分类器比在大训练集上训练少数分类器更快。不过，对于大多数二元分类算法来说，OvR 是首选。
Scikit-Learn 会检测你是否尝试在多分类任务中使用二元分类算法，并根据算法自动运行 OvR 或 OvO。让我们使用 sklearn.svm.SVC 类支持向量机分类器来尝试一下。我们只对前 2,000 张图像进行训练，否则会耗费很长时间：
from sklearn.svm import SVC svm_clf = SVC(random_state=42) svm_clf.fit(X_train[:2000], y_train[:2000]) # y_train, not y_train_5 我们使用从 0 到 9 的原始目标类别（y_train），而不是 5 对其余目标类别（y_train_5）来训练 SVC。由于有 10 个类别（即多于 2 个），Scikit-Learn 使用 OvO 策略训练了 45 个二元分类器。现在，让我们对一幅图像进行预测：</description></item><item><title>图像识别之入门案例之数字识别（Machine Learning 研习十四）</title><link>https://qiucode.cn/article/194/</link><pubDate>Fri, 15 Mar 2024 17:48:03 +0800</pubDate><guid>https://qiucode.cn/article/194/</guid><description>在前面的文章中，我们曾提到最为常见的监督学习任务是回归（预测价值）和分类（预测类别）。我们使用线性回归、决策树和随机森林等各种算法探讨了回归任务，即预测房屋价值。现在，我们将把注意力转向分类系统。
MNIST数据集 我们将使用 MNIST 数据集，这是一组由人类手写的 70,000 张小数字图像。每张图片都标注了所代表的数字。人们对这个数据集的研究非常深入，以至于它经常被称为机器学习的 &amp;ldquo;hello world&amp;rdquo;：每当人们提出一种新的分类算法时，他们都会好奇地想看看这种算法在 MNIST 上的表现如何，而且任何学习机器学习的人迟早都会用到这个数据集。
Scikit-Learn 提供了许多下载流行数据集的辅助函数。MNIST 就是其中之一。以下代码从 OpenML.org 获取 MNIST 数据集：
from sklearn.datasets import fetch_openml mnist = fetch_openml(&amp;#39;mnist_784&amp;#39;, as_frame=False) sklearn.datasets 包主要包含三种类型的函数：fetch_* 函数（如 fetch_openml()）用于下载现实生活中的数据集；load_* 函数用于加载 Scikit-Learn捆绑的小型玩具数据集（因此无需通过互联网下载）；make_* 函数用于生成假数据集，对测试非常有用。生成的数据集通常以 (X, y) 元组的形式返回，其中包含输入数据和目标数据，两者都是 NumPy 数组。其他数据集以 sklearn.utils.Bunch 对象的形式返回，这是一个字典，其条目也可以作为属性访问。它们通常包含以下条目：
&amp;ldquo;DESCR&amp;rdquo;
​ 数据集描述
“data”
​ 输入数据，通常为Numpy二维数组
“target”
​ 标签，通常为Numpy一维数组
fetch_openml() 函数有点不寻常，因为默认情况下，它以 Pandas DataFrame 的形式返回输入，以 Pandas Series 的形式返回标签（除非数据集很稀疏）。但 MNIST 数据集包含图像，而 DataFrame 并不适合图像，因此最好设置 as_frame=False，以 NumPy 数组的形式获取数据。让我们来看看这些数组：
共有 70,000 幅图像，每幅图像有 784 个特征。这是因为每幅图像都是 28 × 28 像素，每个特征只代表一个像素的强度，从 0（白色）到 255（黑色）。让我们来看看数据集中的一个数字（图 3-1）。我们需要做的就是抓取一个实例的特征向量，将其重塑为 28 × 28 数组，然后使用 Matplotlib 的 imshow() 函数显示出来。我们使用 cmap=&amp;quot;binary&amp;quot; 来获取灰度颜色图，其中 0 代表白色，255 代表黑色：</description></item></channel></rss>