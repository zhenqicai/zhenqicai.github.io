<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on 秋码分享</title><link>https://qiucode.cn/tags/ai/</link><description>Recent content in AI on 秋码分享</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Sat, 09 Mar 2024 14:59:44 +0800</lastBuildDate><atom:link href="https://qiucode.cn/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>微调模型（Machine Learning 研习之十二）</title><link>https://qiucode.cn/article/192/</link><pubDate>Sat, 09 Mar 2024 14:59:44 +0800</pubDate><guid>https://qiucode.cn/article/192/</guid><description>现在正处于百模乱战的时期，对于模型微调，想必您是有所了解了，毕竟国外的大语言模型一开源，国内便纷纷基于该模型进行微调，从而开始宣称领先于某某、超越了谁。可到头来，却让人发现他们套壳了国外大语言模型对外开放的API。
好了，我们不说国内各种大模型宣称超过了谁，毕竟，嘴巴长在别人脸上，我们管不了，也管不着，吹牛终将是会露馅的！
当我们需要对开源大模型进行微调时，看看有几种方法可以做到这一点的！
网格搜索 手动调整超参数，直到找到超参数值的完美组合。 这将是一项非常乏味的工作，而且您可能没有时间去探索多种组合。
相反，您可以使用 Scikit-Learn 的 GridSearchCV 类来搜索您。 您需要做的就是告诉它您希望它试验哪些超参数以及要尝试哪些值，它将使用交叉验证来评估超参数值的所有可能组合。 例如，以下代码搜索 RandomForestRegressor 的最佳超参数值组合：
from sklearn.model_selection import GridSearchCV full_pipeline = Pipeline([ (&amp;#34;preprocessing&amp;#34;, preprocessing), (&amp;#34;random_forest&amp;#34;, RandomForestRegressor(random_state=42)), ]) param_grid = [{&amp;#39;preprocessing__geo__n_clusters&amp;#39;: [5, 8, 10], &amp;#39;random_forest__max_features&amp;#39;: [4, 6, 8]}, {&amp;#39;preprocessing__geo__n_clusters&amp;#39;: [10, 15], &amp;#39;random_forest__max_features&amp;#39;: [6, 8, 10]}, ] grid_search = GridSearchCV(full_pipeline, param_grid, cv=3, scoring=&amp;#39;neg_root_mean_squared_error&amp;#39;) grid_search.fit(housing, housing_labels) 请注意，您可以引用管道中任何估计器的任何超参数，即使该估计器嵌套在多个管道和列转换器的深处。 例如，当 Scikit-Learn 看到“preprocessing__geo__n_clusters”时，它会在双下划线处分割该字符串，然后在管道中查找名为“preprocessing”的估计器并找到预处理 ColumnTransformer。 接下来，它在此 ColumnTransformer 中查找名为“geo”的转换器，并找到我们在纬度和经度属性上使用的 ClusterSimilarity 转换器。 然后它找到该变压器的n_clusters超参数。 同样，random_forest__max_features指的是名为“random_forest”的估计器的max_features超参数，这当然是RandomForest模型。
这个param_grid中有两个字典，因此GridSearchCV将首先评估第一个字典中指定的n_clusters和max_features超参数值的所有3×3=9个组合，然后它将尝试第一个字典中指定的所有2×3=6个超参数值组合 第二个字典。 因此，网格搜索总共将探索 9 + 6 = 15 种超参数值组合，并且每个组合都会对管道进行 3 次训练，因为我们使用的是 3 折交叉验证。 这意味着总共将有 15 × 3 = 45 轮训练！ 这可能需要一段时间，但是完成后您可以获得如下参数的最佳组合：</description></item></channel></rss>